---
title:          "Label Noise in Adversarial Training: A Novel Perspective to Study Robust Overfitting"
date:           2022-06-01 00:01:00 +0800
selected:       true
pub:            "Neural Information Processing Systems (NeurIPS)"
# pub_pre:        "Submitted to "
# pub_post:       'Under review.'
pub_last:       ' <span class="badge badge-pill badge-publication badge-success">Oral</span>'
pub_date:       "2022"

abstract: >-
  We show that robust overfitting in adversarially robust deep learning is likely the result of the implicit label noise in adversarial training. Robust overfitting is thus the early stage of an epoch-wise double descent and is not a new phenomenon.
cover:          /assets/images/covers/LabelNoise.png
authors:
  - Chengyu Dong
  - Liyuan Liu
  - Jingbo Shang
links:
  # Code: https://github.com/luost26/academic-homepage
  # Unsplash: https://unsplash.com/photos/sliced-in-half-pineapple--_PLJZmHZzk
  Paper: https://arxiv.org/abs/2110.03135
  Poster: https://drive.google.com/file/d/1CWyHYZt1a0U7qddf21bI0L0ocCcBwuKg/view?usp=sharing
  Slides: https://drive.google.com/file/d/1FX-qfoi6Xpo4fM7z4zFtJtco4zQTPnSi/view?usp=sharing
---
